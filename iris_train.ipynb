{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4fcba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import flags, logging, app\n",
    "from absl.flags import FLAGS\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import math\n",
    "from itertools import product as product\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from modules.anchor import prior_box\n",
    "from modules.utils import set_memory_growth, load_yaml, ProgressBar\n",
    "from modules.models import RetinaFaceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "310459e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"flags.DEFINE_string('gpu', '0', 'which gpu to use'): This line defines a command-line flag named 'gpu'. \\n    The flags.DEFINE_string function is used to create a string-typed flag with a default value of '0' and \\n    a description 'which gpu to use'. \\n    This flag will allow you to specify the GPU to use when running the script.\\n    For example, if you run the script with the command: python script.py --gpu=1, \\n    the value '1' will be assigned to CUDA_VISIBLE_DEVICES, and the script will use the GPU with the ID 1 for \\n    TensorFlow operations. If you don't provide a value for the 'gpu' flag, it will default to '0', and the \\n    script will use the GPU with ID 0.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for name in list(FLAGS):\n",
    "      delattr(FLAGS, name)\n",
    "flags.DEFINE_string('cfg_path', './configs/retinaface_mbv2.yaml', 'path to config file')\n",
    "\n",
    "\"\"\"flags.DEFINE_string('gpu', '0', 'which gpu to use'): This line defines a command-line flag named 'gpu'. \n",
    "    The flags.DEFINE_string function is used to create a string-typed flag with a default value of '0' and \n",
    "    a description 'which gpu to use'. \n",
    "    This flag will allow you to specify the GPU to use when running the script.\n",
    "    For example, if you run the script with the command: python script.py --gpu=1, \n",
    "    the value '1' will be assigned to CUDA_VISIBLE_DEVICES, and the script will use the GPU with the ID 1 for \n",
    "    TensorFlow operations. If you don't provide a value for the 'gpu' flag, it will default to '0', and the \n",
    "    script will use the GPU with ID 0.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da83745b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' sets the environment variable TF_CPP_MIN_LOG_LEVEL to the value '3'.\\n\\nThis environment variable controls the logging verbosity of TensorFlow. \\nHere's what each log level value represents:\\n\\n    0: Shows all logs (default behavior).\\n    1: Shows only INFO-level logs.\\n    2: Shows only WARNING-level logs.\\n    3: Shows only ERROR-level logs.\\n    4: Disables all logs.\\n\\nBy setting TF_CPP_MIN_LOG_LEVEL to '3', you are instructing TensorFlow to display only ERROR-level logs and \\nsuppress INFO and WARNING-level logs. \\nThis is useful if you want to reduce the amount of console output and focus on the most critical log messages.\\n\\nThis environment variable is specific to TensorFlow and controls the verbosity of TensorFlow's own log messages.\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "FLAGS(sys.argv)\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "\"\"\"os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' sets the environment variable TF_CPP_MIN_LOG_LEVEL to the value '3'.\n",
    "\n",
    "This environment variable controls the logging verbosity of TensorFlow. \n",
    "Here's what each log level value represents:\n",
    "\n",
    "    0: Shows all logs (default behavior).\n",
    "    1: Shows only INFO-level logs.\n",
    "    2: Shows only WARNING-level logs.\n",
    "    3: Shows only ERROR-level logs.\n",
    "    4: Disables all logs.\n",
    "\n",
    "By setting TF_CPP_MIN_LOG_LEVEL to '3', you are instructing TensorFlow to display only ERROR-level logs and \n",
    "suppress INFO and WARNING-level logs. \n",
    "This is useful if you want to reduce the amount of console output and focus on the most critical log messages.\n",
    "\n",
    "This environment variable is specific to TensorFlow and controls the verbosity of TensorFlow's own log messages.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "173c8624",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = tf.get_logger()\n",
    "\"\"\"The tf.get_logger() function is a utility provided by TensorFlow to \n",
    "retrieve a logger object that can be used for logging messages within your TensorFlow code.\n",
    "\"\"\"\n",
    "\n",
    "logger.disabled = True\n",
    "logger.setLevel(logging.FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be3033fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "set_memory_growth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23b24095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    }
   ],
   "source": [
    "cfg = load_yaml(FLAGS.cfg_path)\n",
    "print(cfg['init_lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a2cc26",
   "metadata": {},
   "source": [
    "## define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f20a7f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RetinaFaceModel\"\n",
      "______________________________________________________________________________________________________________\n",
      " Layer (type)                       Output Shape            Param #      Connected to                         \n",
      "==============================================================================================================\n",
      " input_image (InputLayer)           [(None, 300, 400, 3)]   0            []                                   \n",
      "                                                                                                              \n",
      " tf.math.truediv (TFOpLambda)       (None, 300, 400, 3)     0            ['input_image[0][0]']                \n",
      "                                                                                                              \n",
      " tf.math.subtract (TFOpLambda)      (None, 300, 400, 3)     0            ['tf.math.truediv[0][0]']            \n",
      "                                                                                                              \n",
      " MobileNetV2_extrator (Functional)  ((None, 38, 50, 192),   1518464      ['tf.math.subtract[0][0]']           \n",
      "                                     (None, 19, 25, 576),                                                     \n",
      "                                     (None, 10, 13, 960))                                                     \n",
      "                                                                                                              \n",
      " FPN (FPN)                          ((None, 38, 50, 64),    185600       ['MobileNetV2_extrator[0][0]',       \n",
      "                                     (None, 19, 25, 64),                  'MobileNetV2_extrator[0][1]',       \n",
      "                                     (None, 10, 13, 64))                  'MobileNetV2_extrator[0][2]']       \n",
      "                                                                                                              \n",
      " SSH_0 (SSH)                        (None, 38, 50, 64)      34944        ['FPN[0][0]']                        \n",
      "                                                                                                              \n",
      " SSH_1 (SSH)                        (None, 19, 25, 64)      34944        ['FPN[0][1]']                        \n",
      "                                                                                                              \n",
      " SSH_2 (SSH)                        (None, 10, 13, 64)      34944        ['FPN[0][2]']                        \n",
      "                                                                                                              \n",
      " ClassHead_0 (ClassHead)            (None, 3800, 2)         260          ['SSH_0[0][0]']                      \n",
      "                                                                                                              \n",
      " ClassHead_1 (ClassHead)            (None, 950, 2)          260          ['SSH_1[0][0]']                      \n",
      "                                                                                                              \n",
      " ClassHead_2 (ClassHead)            (None, 260, 2)          260          ['SSH_2[0][0]']                      \n",
      "                                                                                                              \n",
      " BboxHead_0 (BboxHead)              (None, 3800, 4)         520          ['SSH_0[0][0]']                      \n",
      "                                                                                                              \n",
      " BboxHead_1 (BboxHead)              (None, 950, 4)          520          ['SSH_1[0][0]']                      \n",
      "                                                                                                              \n",
      " BboxHead_2 (BboxHead)              (None, 260, 4)          520          ['SSH_2[0][0]']                      \n",
      "                                                                                                              \n",
      " LandmarkHead_0 (LandmarkHead)      (None, 3800, 4)         520          ['SSH_0[0][0]']                      \n",
      "                                                                                                              \n",
      " LandmarkHead_1 (LandmarkHead)      (None, 950, 4)          520          ['SSH_1[0][0]']                      \n",
      "                                                                                                              \n",
      " LandmarkHead_2 (LandmarkHead)      (None, 260, 4)          520          ['SSH_2[0][0]']                      \n",
      "                                                                                                              \n",
      " tf.concat_2 (TFOpLambda)           (None, 5010, 2)         0            ['ClassHead_0[0][0]',                \n",
      "                                                                          'ClassHead_1[0][0]',                \n",
      "                                                                          'ClassHead_2[0][0]']                \n",
      "                                                                                                              \n",
      " tf.concat (TFOpLambda)             (None, 5010, 4)         0            ['BboxHead_0[0][0]',                 \n",
      "                                                                          'BboxHead_1[0][0]',                 \n",
      "                                                                          'BboxHead_2[0][0]']                 \n",
      "                                                                                                              \n",
      " tf.concat_1 (TFOpLambda)           (None, 5010, 4)         0            ['LandmarkHead_0[0][0]',             \n",
      "                                                                          'LandmarkHead_1[0][0]',             \n",
      "                                                                          'LandmarkHead_2[0][0]']             \n",
      "                                                                                                              \n",
      " softmax (Softmax)                  (None, 5010, 2)         0            ['tf.concat_2[0][0]']                \n",
      "                                                                                                              \n",
      "==============================================================================================================\n",
      "Total params: 1,812,796\n",
      "Trainable params: 1,784,508\n",
      "Non-trainable params: 28,288\n",
      "______________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RetinaFaceModel(cfg, training=True)\n",
    "model.summary(line_length=110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cae7a6",
   "metadata": {},
   "source": [
    "## define prior box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b67dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = prior_box((cfg['input_height'], cfg['input_width']),\n",
    "                       cfg['min_sizes'],  cfg['steps'], cfg['clip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37d8cc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5010"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba0dc10",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8519969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(cfg, priors, shuffle=True, buffer_size=10240):\n",
    "    \"\"\"load dataset\"\"\"\n",
    "    logging.info(\"load dataset from {}\".format(cfg['dataset_path']))\n",
    "    dataset = load_tfrecord_dataset(\n",
    "        tfrecord_name=cfg['dataset_path'],\n",
    "        batch_size=cfg['batch_size'],\n",
    "        \n",
    "        using_bin=cfg['using_bin'],\n",
    "        using_flip=cfg['using_flip'],\n",
    "        using_distort=cfg['using_distort'],\n",
    "        using_encoding=True,\n",
    "        priors=priors,\n",
    "        match_thresh=cfg['match_thresh'],\n",
    "        ignore_thresh=cfg['ignore_thresh'],\n",
    "        variances=cfg['variances'],\n",
    "        shuffle=shuffle,\n",
    "        buffer_size=buffer_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2af6ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.anchor import encode_tf\n",
    "def _parse_tfrecord(using_bin, using_flip, using_distort,\n",
    "                    using_encoding, priors, match_thresh, ignore_thresh,\n",
    "                    variances):\n",
    "    def parse_tfrecord(tfrecord):\n",
    "        features = {\n",
    "            'image/img_name': tf.io.FixedLenFeature([], tf.string),\n",
    "            'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
    "            'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
    "            'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
    "            'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
    "            'image/object/landmark0/x': tf.io.VarLenFeature(tf.float32),\n",
    "            'image/object/landmark0/y': tf.io.VarLenFeature(tf.float32),\n",
    "            'image/object/landmark1/x': tf.io.VarLenFeature(tf.float32),\n",
    "            'image/object/landmark1/y': tf.io.VarLenFeature(tf.float32),\n",
    "           \n",
    "            'image/object/landmark/valid': tf.io.VarLenFeature(tf.float32)}\n",
    "        if using_bin:\n",
    "            features['image/encoded'] = tf.io.FixedLenFeature([], tf.string)\n",
    "            x = tf.io.parse_single_example(tfrecord, features)\n",
    "            img = tf.image.decode_image(x['image/encoded'], channels=3)\n",
    "        else:\n",
    "            features['image/img_path'] = tf.io.FixedLenFeature([], tf.string)\n",
    "            x = tf.io.parse_single_example(tfrecord, features)\n",
    "            image_encoded = tf.io.read_file(x['image/img_path'])\n",
    "            img = tf.image.decode_image(image_encoded, channels=3)\n",
    "\n",
    "        labels = tf.stack(\n",
    "            [tf.sparse.to_dense(x['image/object/bbox/xmin']),\n",
    "             tf.sparse.to_dense(x['image/object/bbox/ymin']),\n",
    "             tf.sparse.to_dense(x['image/object/bbox/xmax']),\n",
    "             tf.sparse.to_dense(x['image/object/bbox/ymax']),\n",
    "             tf.sparse.to_dense(x['image/object/landmark0/x']),\n",
    "             tf.sparse.to_dense(x['image/object/landmark0/y']),\n",
    "             tf.sparse.to_dense(x['image/object/landmark1/x']),\n",
    "             tf.sparse.to_dense(x['image/object/landmark1/y']),\n",
    "             \n",
    "             tf.sparse.to_dense(x['image/object/landmark/valid'])], axis=1)\n",
    "\n",
    "        img, labels = _transform_data(using_flip, using_distort, using_encoding, priors,\n",
    "            match_thresh, ignore_thresh, variances)(img, labels)\n",
    "\n",
    "        return img, labels\n",
    "    return parse_tfrecord\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def _transform_data(using_flip, using_distort, using_encoding, priors,\n",
    "                    match_thresh, ignore_thresh, variances):\n",
    "    def transform_data(img, labels):\n",
    "        img = tf.cast(img, tf.float32)\n",
    "\n",
    "        # randomly crop\n",
    "        #img, labels = _crop(img, labels)\n",
    "\n",
    "        # padding to square\n",
    "        #img = _pad_to_square(img)\n",
    "\n",
    "\n",
    "        # randomly left-right flip\n",
    "        if using_flip:\n",
    "            img, labels = _flip(img, labels)\n",
    "\n",
    "        # distort\n",
    "        if using_distort:\n",
    "            img = _distort(img)\n",
    "\n",
    "        # encode labels to feature targets\n",
    "        if using_encoding:\n",
    "            labels = encode_tf(labels=labels, priors=priors,\n",
    "                               match_thresh=match_thresh,\n",
    "                               ignore_thresh=ignore_thresh,\n",
    "                               variances=variances)\n",
    "\n",
    "        return img, labels\n",
    "    return transform_data\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def load_tfrecord_dataset(tfrecord_name, batch_size, \n",
    "                          using_bin=True, using_flip=True, using_distort=True,\n",
    "                          using_encoding=True, priors=None, match_thresh=0.45,\n",
    "                          ignore_thresh=0.3, variances=[0.1, 0.2],\n",
    "                          shuffle=True, buffer_size=10240):\n",
    "    \"\"\"load dataset from tfrecord\"\"\"\n",
    "    if not using_encoding:\n",
    "        assert batch_size == 1  # dynamic data len when using_encoding\n",
    "    else:\n",
    "        assert priors is not None\n",
    "\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_name)\n",
    "    raw_dataset = raw_dataset.repeat()\n",
    "    if shuffle:\n",
    "        raw_dataset = raw_dataset.shuffle(buffer_size=buffer_size)\n",
    "    dataset = raw_dataset.map(\n",
    "        _parse_tfrecord(using_bin, using_flip, using_distort,\n",
    "                        using_encoding, priors, match_thresh, ignore_thresh,\n",
    "                        variances),\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(\n",
    "        buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def _flip(img, labels):\n",
    "    flip_case = tf.random.uniform([], 0, 2, dtype=tf.int32)\n",
    "\n",
    "    def flip_func():\n",
    "        flip_img = tf.image.flip_left_right(img)\n",
    "        flip_labels = tf.stack([1 - labels[:, 2],  labels[:, 1],\n",
    "                                1 - labels[:, 0],  labels[:, 3],\n",
    "                                1 - labels[:, 6],  labels[:, 7],\n",
    "                                1 - labels[:, 4],  labels[:, 5],\n",
    "                                \n",
    "                                labels[:, 8]], axis=1)\n",
    "\n",
    "        return flip_img, flip_labels\n",
    "\n",
    "    img, labels = tf.case([(tf.equal(flip_case, 0), flip_func)],\n",
    "                          default=lambda: (img, labels))\n",
    "\n",
    "    return img, labels\n",
    "\n",
    "\n",
    "def _crop(img, labels, max_loop=250):\n",
    "    shape = tf.shape(img)\n",
    "\n",
    "    def matrix_iof(a, b):\n",
    "        \"\"\"\n",
    "        return iof of a and b, numpy version for data augenmentation\n",
    "        \"\"\"\n",
    "        lt = tf.math.maximum(a[:, tf.newaxis, :2], b[:, :2])\n",
    "        rb = tf.math.minimum(a[:, tf.newaxis, 2:], b[:, 2:])\n",
    "\n",
    "        area_i = tf.math.reduce_prod(rb - lt, axis=2) * \\\n",
    "            tf.cast(tf.reduce_all(lt < rb, axis=2), tf.float32)\n",
    "        area_a = tf.math.reduce_prod(a[:, 2:] - a[:, :2], axis=1)\n",
    "        return area_i / tf.math.maximum(area_a[:, tf.newaxis], 1)\n",
    "\n",
    "    def crop_loop_body(i, img, labels):\n",
    "        valid_crop = tf.constant(1, tf.int32)\n",
    "\n",
    "        pre_scale = tf.constant([0.3, 0.45, 0.6, 0.8, 1.0], dtype=tf.float32)\n",
    "        scale = pre_scale[tf.random.uniform([], 0, 5, dtype=tf.int32)]\n",
    "        short_side = tf.cast(tf.minimum(shape[0], shape[1]), tf.float32)\n",
    "        h = w = tf.cast(scale * short_side, tf.int32)\n",
    "        h_offset = tf.random.uniform([], 0, shape[0] - h + 1, dtype=tf.int32)\n",
    "        w_offset = tf.random.uniform([], 0, shape[1] - w + 1, dtype=tf.int32)\n",
    "        roi = tf.stack([w_offset, h_offset, w_offset + w, h_offset + h])\n",
    "        roi = tf.cast(roi, tf.float32)\n",
    "\n",
    "        value = matrix_iof(labels[:, :4], roi[tf.newaxis])\n",
    "        valid_crop = tf.cond(tf.math.reduce_any(value >= 1),\n",
    "                             lambda: valid_crop, lambda: 0)\n",
    "\n",
    "        centers = (labels[:, :2] + labels[:, 2:4]) / 2\n",
    "        mask_a = tf.reduce_all(\n",
    "            tf.math.logical_and(roi[:2] < centers, centers < roi[2:]),\n",
    "            axis=1)\n",
    "        labels_t = tf.boolean_mask(labels, mask_a)\n",
    "        valid_crop = tf.cond(tf.reduce_any(mask_a),\n",
    "                             lambda: valid_crop, lambda: 0)\n",
    "\n",
    "        img_t = img[h_offset:h_offset + h, w_offset:w_offset + w, :]\n",
    "        h_offset = tf.cast(h_offset, tf.float32)\n",
    "        w_offset = tf.cast(w_offset, tf.float32)\n",
    "        labels_t = tf.stack(\n",
    "            [labels_t[:, 0] - w_offset,  labels_t[:, 1] - h_offset,\n",
    "             labels_t[:, 2] - w_offset,  labels_t[:, 3] - h_offset,\n",
    "             labels_t[:, 4] - w_offset,  labels_t[:, 5] - h_offset,\n",
    "             labels_t[:, 6] - w_offset,  labels_t[:, 7] - h_offset,\n",
    "             labels_t[:, 8] - w_offset,  labels_t[:, 9] - h_offset,\n",
    "             labels_t[:, 10] - w_offset, labels_t[:, 11] - h_offset,\n",
    "             labels_t[:, 12] - w_offset, labels_t[:, 13] - h_offset,\n",
    "             labels_t[:, 14]], axis=1)\n",
    "\n",
    "        return tf.cond(valid_crop == 1,\n",
    "                       lambda: (max_loop, img_t, labels_t),\n",
    "                       lambda: (i + 1, img, labels))\n",
    "\n",
    "    _, img, labels = tf.while_loop(\n",
    "        lambda i, img, labels: tf.less(i, max_loop),\n",
    "        crop_loop_body,\n",
    "        [tf.constant(-1), img, labels],\n",
    "        shape_invariants=[tf.TensorShape([]),\n",
    "                          tf.TensorShape([None, None, 3]),\n",
    "                          tf.TensorShape([None, 15])])\n",
    "\n",
    "    return img, labels\n",
    "\n",
    "\n",
    "def _pad_to_square(img):\n",
    "    height = tf.shape(img)[0]\n",
    "    width = tf.shape(img)[1]\n",
    "\n",
    "    def pad_h():\n",
    "        img_pad_h = tf.ones([width - height, width, 3]) * \\\n",
    "            tf.reduce_mean(img, axis=[0, 1], keepdims=True)\n",
    "        return tf.concat([img, img_pad_h], axis=0)\n",
    "\n",
    "    def pad_w():\n",
    "        img_pad_w = tf.ones([height, height - width, 3]) * \\\n",
    "            tf.reduce_mean(img, axis=[0, 1], keepdims=True)\n",
    "        return tf.concat([img, img_pad_w], axis=1)\n",
    "\n",
    "    img = tf.case([(tf.greater(height, width), pad_w),\n",
    "                   (tf.less(height, width), pad_h)], default=lambda: img)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def _resize(img, labels, img_dim):\n",
    "    w_f = tf.cast(tf.shape(img)[1], tf.float32)\n",
    "    h_f = tf.cast(tf.shape(img)[0], tf.float32)\n",
    "    locs = tf.stack([labels[:, 0] / w_f,  labels[:, 1] / h_f,\n",
    "                     labels[:, 2] / w_f,  labels[:, 3] / h_f,\n",
    "                     labels[:, 4] / w_f,  labels[:, 5] / h_f,\n",
    "                     labels[:, 6] / w_f,  labels[:, 7] / h_f,\n",
    "                     labels[:, 8] / w_f,  labels[:, 9] / h_f,\n",
    "                     labels[:, 10] / w_f, labels[:, 11] / h_f,\n",
    "                     labels[:, 12] / w_f, labels[:, 13] / h_f], axis=1)\n",
    "    locs = tf.clip_by_value(locs, 0, 1)\n",
    "    labels = tf.concat([locs, labels[:, 14][:, tf.newaxis]], axis=1)\n",
    "\n",
    "    resize_case = tf.random.uniform([], 0, 5, dtype=tf.int32)\n",
    "\n",
    "    def resize(method):\n",
    "        def _resize():\n",
    "            return tf.image.resize(\n",
    "                img, [img_dim, img_dim], method=method, antialias=True)\n",
    "        return _resize\n",
    "\n",
    "    img = tf.case([(tf.equal(resize_case, 0), resize('bicubic')),\n",
    "                   (tf.equal(resize_case, 1), resize('area')),\n",
    "                   (tf.equal(resize_case, 2), resize('nearest')),\n",
    "                   (tf.equal(resize_case, 3), resize('lanczos3'))],\n",
    "                  default=resize('bilinear'))\n",
    "\n",
    "    return img, labels\n",
    "\n",
    "\n",
    "def _distort(img):\n",
    "    img = tf.image.random_brightness(img, 0.4)\n",
    "    img = tf.image.random_contrast(img, 0.5, 1.5)\n",
    "    img = tf.image.random_saturation(img, 0.5, 1.5)\n",
    "    img = tf.image.random_hue(img, 0.1)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e6bf954",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(cfg, priors, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76783c30",
   "metadata": {},
   "source": [
    "## define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5703af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiStepLR(initial_learning_rate, lr_steps, lr_rate, name='MultiStepLR'):\n",
    "    \"\"\"Multi-steps learning rate scheduler.\"\"\"\n",
    "    lr_steps_value = [initial_learning_rate]\n",
    "    for _ in range(len(lr_steps)):\n",
    "        lr_steps_value.append(lr_steps_value[-1] * lr_rate)\n",
    "    return tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "        boundaries=lr_steps, values=lr_steps_value)\n",
    "\n",
    "\n",
    "def MultiStepWarmUpLR(initial_learning_rate, lr_steps, lr_rate,\n",
    "                      warmup_steps=0., min_lr=0.,\n",
    "                      name='MultiStepWarmUpLR'):\n",
    "    \"\"\"Multi-steps warm up learning rate scheduler.\"\"\"\n",
    "    assert warmup_steps <= lr_steps[0]\n",
    "    assert min_lr <= initial_learning_rate\n",
    "    lr_steps_value = [initial_learning_rate]\n",
    "    for _ in range(len(lr_steps)):\n",
    "        lr_steps_value.append(lr_steps_value[-1] * lr_rate)\n",
    "    return PiecewiseConstantWarmUpDecay(\n",
    "        boundaries=lr_steps, values=lr_steps_value, warmup_steps=warmup_steps,\n",
    "        min_lr=min_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f718cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PiecewiseConstantWarmUpDecay(\n",
    "        tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \"\"\"A LearningRateSchedule wiht warm up schedule.\n",
    "    Modified from tf.keras.optimizers.schedules.PiecewiseConstantDecay\"\"\"\n",
    "\n",
    "    def __init__(self, boundaries, values, warmup_steps, min_lr,\n",
    "                 name=None):\n",
    "        super(PiecewiseConstantWarmUpDecay, self).__init__()\n",
    "\n",
    "        if len(boundaries) != len(values) - 1:\n",
    "            raise ValueError(\n",
    "                    \"The length of boundaries should be 1 less than the\"\n",
    "                    \"length of values\")\n",
    "\n",
    "        self.boundaries = boundaries\n",
    "        self.values = values\n",
    "        self.name = name\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.min_lr = min_lr\n",
    "\n",
    "    def __call__(self, step):\n",
    "        with tf.name_scope(self.name or \"PiecewiseConstantWarmUp\"):\n",
    "            step = tf.cast(tf.convert_to_tensor(step), tf.float32)\n",
    "            pred_fn_pairs = []\n",
    "            warmup_steps = self.warmup_steps\n",
    "            boundaries = self.boundaries\n",
    "            values = self.values\n",
    "            min_lr = self.min_lr\n",
    "\n",
    "            pred_fn_pairs.append(\n",
    "                (step <= warmup_steps,\n",
    "                 lambda: min_lr + step * (values[0] - min_lr) / warmup_steps))\n",
    "            pred_fn_pairs.append(\n",
    "                (tf.logical_and(step <= boundaries[0],\n",
    "                                step > warmup_steps),\n",
    "                 lambda: tf.constant(values[0])))\n",
    "            pred_fn_pairs.append(\n",
    "                (step > boundaries[-1], lambda: tf.constant(values[-1])))\n",
    "\n",
    "            for low, high, v in zip(boundaries[:-1], boundaries[1:],\n",
    "                                    values[1:-1]):\n",
    "                pred = (step > low) & (step <= high)\n",
    "                pred_fn_pairs.append((pred, lambda v=v: tf.constant(v)))\n",
    "\n",
    "            # The default isn't needed here because our conditions are mutually\n",
    "            # exclusive and exhaustive, but tf.case requires it.\n",
    "            return tf.case(pred_fn_pairs, lambda: tf.constant(values[0]),\n",
    "                           exclusive=True)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "                \"boundaries\": self.boundaries,\n",
    "                \"values\": self.values,\n",
    "                \"warmup_steps\": self.warmup_steps,\n",
    "                \"min_lr\": self.min_lr,\n",
    "                \"name\": self.name\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3884d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.legacy import SGD\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "steps_per_epoch = cfg['dataset_len'] // cfg['batch_size']\n",
    "learning_rate = MultiStepWarmUpLR(\n",
    "    initial_learning_rate=cfg['init_lr'],\n",
    "    lr_steps=[e * steps_per_epoch for e in cfg['lr_decay_epoch']],\n",
    "    lr_rate=cfg['lr_rate'],\n",
    "    warmup_steps=cfg['warmup_epoch'] * steps_per_epoch,\n",
    "    min_lr=cfg['min_lr'])\n",
    "optimizer = SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714de60d",
   "metadata": {},
   "source": [
    "## define losses function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ada545b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _smooth_l1_loss(y_true, y_pred):\n",
    "    t = tf.abs(y_pred - y_true)\n",
    "    return tf.where(t < 1, 0.5 * t ** 2, t - 0.5)\n",
    "\"\"\"The final output tensor will have the same shape as t. \n",
    "    If an element of t is less than 1, the corresponding element in the output tensor will be 0.5 * t ** 2. \n",
    "    If an element of t is greater than or equal to 1, the corresponding element will be t - 0.5.\"\"\"\n",
    "\n",
    "\n",
    "def MultiBoxLoss(num_class=2, neg_pos_ratio=3):\n",
    "    \"\"\"multi-box loss\"\"\"\n",
    "    def multi_box_loss(y_true, y_pred):\n",
    "        num_batch = tf.shape(y_true)[0]\n",
    "        num_prior = tf.shape(y_true)[1]\n",
    "        \n",
    "        print(num_prior)\n",
    "\n",
    "        loc_pred = tf.reshape(y_pred[0], [num_batch * num_prior, 4])\n",
    "        landm_pred = tf.reshape(y_pred[1], [num_batch * num_prior, 4])\n",
    "        class_pred = tf.reshape(y_pred[2], [num_batch * num_prior, num_class])\n",
    "        loc_true = tf.reshape(y_true[..., :4], [num_batch * num_prior, 4])\n",
    "        landm_true = tf.reshape(y_true[..., 4:8], [num_batch * num_prior, 4])\n",
    "        landm_valid = tf.reshape(y_true[..., 8], [num_batch * num_prior, 1])\n",
    "        class_true = tf.reshape(y_true[..., 9], [num_batch * num_prior, 1])\n",
    "\n",
    "        # define filter mask: class_true = 1 (pos), 0 (neg), -1 (ignore)\n",
    "        #                     landm_valid = 1 (w landm), 0 (w/o landm)\n",
    "        mask_pos = tf.equal(class_true, 1)\n",
    "        mask_neg = tf.equal(class_true, 0)\n",
    "        mask_landm = tf.logical_and(tf.equal(landm_valid, 1), mask_pos)\n",
    "\n",
    "        # landm loss (smooth L1)\n",
    "        mask_landm_b = tf.broadcast_to(mask_landm, tf.shape(landm_true))\n",
    "        loss_landm = _smooth_l1_loss(tf.boolean_mask(landm_true, mask_landm_b),\n",
    "                                     tf.boolean_mask(landm_pred, mask_landm_b))\n",
    "        loss_landm = tf.reduce_mean(loss_landm)\n",
    "\n",
    "        # localization loss (smooth L1)\n",
    "        mask_pos_b = tf.broadcast_to(mask_pos, tf.shape(loc_true))\n",
    "        loss_loc = _smooth_l1_loss(tf.boolean_mask(loc_true, mask_pos_b),\n",
    "                                   tf.boolean_mask(loc_pred, mask_pos_b))\n",
    "        loss_loc = tf.reduce_mean(loss_loc)\n",
    "\n",
    "        # classification loss (crossentropy)\n",
    "        # 1. compute max conf across batch for hard negative mining\n",
    "        loss_class = tf.where(mask_neg,\n",
    "                              1 - class_pred[:, 0][..., tf.newaxis], 0)\n",
    "\n",
    "        # 2. hard negative mining\n",
    "        loss_class = tf.reshape(loss_class, [num_batch, num_prior])\n",
    "        loss_class_idx = tf.argsort(loss_class, axis=1, direction='DESCENDING')\n",
    "        loss_class_idx_rank = tf.argsort(loss_class_idx, axis=1)\n",
    "        mask_pos_per_batch = tf.reshape(mask_pos, [num_batch, num_prior])\n",
    "        num_pos_per_batch = tf.reduce_sum(\n",
    "                tf.cast(mask_pos_per_batch, tf.float32), 1, keepdims=True)\n",
    "        num_pos_per_batch = tf.maximum(num_pos_per_batch, 1)\n",
    "        num_neg_per_batch = tf.minimum(neg_pos_ratio * num_pos_per_batch,\n",
    "                                       tf.cast(num_prior, tf.float32) - 1)\n",
    "        mask_hard_neg = tf.reshape(\n",
    "            tf.cast(loss_class_idx_rank, tf.float32) < num_neg_per_batch,\n",
    "            [num_batch * num_prior, 1])\n",
    "\n",
    "        # 3. classification loss including positive and negative examples\n",
    "        loss_class_mask = tf.logical_or(mask_pos, mask_hard_neg)\n",
    "        loss_class_mask_b = tf.broadcast_to(loss_class_mask,\n",
    "                                            tf.shape(class_pred))\n",
    "        filter_class_true = tf.boolean_mask(tf.cast(mask_pos, tf.float32),\n",
    "                                            loss_class_mask)\n",
    "        filter_class_pred = tf.boolean_mask(class_pred, loss_class_mask_b)\n",
    "        filter_class_pred = tf.reshape(filter_class_pred, [-1, num_class])\n",
    "        loss_class = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "            y_true=filter_class_true, y_pred=filter_class_pred)\n",
    "        loss_class = tf.reduce_mean(loss_class)\n",
    "\n",
    "        return loss_loc, loss_landm, loss_class\n",
    "\n",
    "    return multi_box_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e91a441",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_box_loss = MultiBoxLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4981c71a",
   "metadata": {},
   "source": [
    "## load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eee29228",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './checkpoints_new/' + cfg['sub_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d85923ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.train.Checkpoint(step=tf.Variable(0, name='step'),\n",
    "                                 optimizer=optimizer,\n",
    "                                 model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e773574",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = tf.train.CheckpointManager(checkpoint=checkpoint,\n",
    "                                         directory=checkpoint_dir,\n",
    "                                         max_to_keep=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b359e227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] load ckpt from ./checkpoints_new/retinaface_mbv2/ckpt-3 at step 3000.\n"
     ]
    }
   ],
   "source": [
    "if manager.latest_checkpoint:\n",
    "    checkpoint.restore(manager.latest_checkpoint)\n",
    "    print('[*] load ckpt from {} at step {}.'.format(\n",
    "        manager.latest_checkpoint, checkpoint.step.numpy()))\n",
    "else:\n",
    "    print(\"[*] training from scratch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f50a51",
   "metadata": {},
   "source": [
    "## define training step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "febdc538",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inputs, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "\n",
    "        losses = {}\n",
    "        losses['reg'] = tf.reduce_sum(model.losses)\n",
    "        losses['loc'], losses['landm'], losses['class'] = \\\n",
    "            multi_box_loss(labels, predictions)\n",
    "        total_loss = tf.add_n([l for l in losses.values()])\n",
    "\n",
    "    grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    return total_loss, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d8e2a5",
   "metadata": {},
   "source": [
    "## training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cd39820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_1:0\", shape=(), dtype=int32)\n",
      "Tensor(\"strided_slice_1:0\", shape=(), dtype=int32)\n",
      "Training [>>>>>>>>>>>>>>>>>>>>>    ] 689/805, epoch=4/100, loss=nan, lr=1.0e-03  5.0 step/secc"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m checkpoint\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39massign_add(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m steps \u001b[38;5;241m=\u001b[39m checkpoint\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 10\u001b[0m total_loss, losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m prog_bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, loss=\u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m, lr=\u001b[39m\u001b[38;5;132;01m{:.1e}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     13\u001b[0m     ((steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m steps_per_epoch) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     14\u001b[0m     total_loss\u001b[38;5;241m.\u001b[39mnumpy(), optimizer\u001b[38;5;241m.\u001b[39mlr(steps)\u001b[38;5;241m.\u001b[39mnumpy()))\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m steps \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "summary_writer = tf.summary.create_file_writer('./logs/' + cfg['sub_name'])\n",
    "remain_steps = max(\n",
    "    steps_per_epoch * cfg['epoch'] - checkpoint.step.numpy(), 0)\n",
    "prog_bar = ProgressBar(steps_per_epoch,checkpoint.step.numpy() % steps_per_epoch)\n",
    "\n",
    "for inputs, labels in train_dataset.take(remain_steps):\n",
    "    checkpoint.step.assign_add(1)\n",
    "    steps = checkpoint.step.numpy()\n",
    "\n",
    "    total_loss, losses = train_step(inputs, labels)\n",
    "    \n",
    "    prog_bar.update(\"epoch={}/{}, loss={:.4f}, lr={:.1e}\".format(\n",
    "        ((steps - 1) // steps_per_epoch) + 1, cfg['epoch'],\n",
    "        total_loss.numpy(), optimizer.lr(steps).numpy()))\n",
    "    \n",
    "    if steps % 10 == 0:\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar(\n",
    "                'loss/total_loss', total_loss, step=steps)\n",
    "            for k, l in losses.items():\n",
    "                tf.summary.scalar('loss/{}'.format(k), l, step=steps)\n",
    "            tf.summary.scalar(\n",
    "                'learning_rate', optimizer.lr(steps), step=steps)\n",
    "\n",
    "    if steps % cfg['save_steps'] == 0:\n",
    "        manager.save()\n",
    "        print(\"\\n[*] save ckpt file at {}\".format(\n",
    "            manager.latest_checkpoint))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb891456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f27fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
